groups:

- name: Service alerts
  rules:

  # Alert for any instance that is unreachable for > 2 minutes.
  - alert: Service Instance Down
    expr: up == 0
    for: 2m
    labels:
      severity: warn
    annotations:
      summary: "Instance {{ $labels.instance }} down"
      description: "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 2 minutes."

  ## Absent() Method returns an absolute value of a result
  ## time() Method returns the actual epoch time
  ## container_last_seen() Methods is provided by cadvisor
  # Service FRONT is down ? Alerts if not data exists
  - alert: Service FRONT Down
    expr: absent(time() - container_last_seen{name="service-front"}) < 5
    for: 15s
    labels:
      severity: critical
    annotations:
      summary: "Instance {{ $labels.instance }} down"
      description: "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 15s."

  # Service Gateway is down ? Alerts if not data exists
  - alert: Service GATEWAY Down
    expr: absent(time() - container_last_seen{name="service-gateway"}) < 5
    for: 15s
    labels:
      severity: critical
    annotations:
      summary: "Instance {{ $labels.instance }} down"
      description: "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 15s."

  # Service Postgres is down ? Alerts if not data exists
  - alert: Service POSTGRES Down
    expr: absent(time() - container_last_seen{name="postgres"}) < 5
    for: 15s
    labels:
      severity: critical
    annotations:
      summary: "Instance {{ $labels.instance }} down"
      description: "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 15s."

  # Service Rabbitmq is down ? Alerts if not data exists
  - alert: Service RABBITMQ Down
    expr: absent(time() - container_last_seen{name="rabbitmq"}) < 5
    for: 15s
    labels:
      severity: critical
    annotations:
      summary: "Instance {{ $labels.instance }} down"
      description: "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 15s."

  # Service Redis is down ? Alerts if not data exists
  - alert: Service REDIS Down
    expr: absent(time() - container_last_seen{name="redis"}) < 5
    for: 15s
    labels:
      severity: critical
    annotations:
      summary: "Instance {{ $labels.instance }} down"
      description: "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 15s."

  # Service Keycloak is down ? Alerts if not data exists
  - alert: Service KEYCLOAK Down
    expr: absent(time() - container_last_seen{name="keycloak"}) < 5
    for: 15s
    labels:
      severity: critical
    annotations:
      summary: "Instance {{ $labels.instance }} down"
      description: "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 15s."

- name: Common alerts
  rules:

  # Disk Usage - Monitoring (preventive)
  - alert: DiskWillFillIn4Hours
    expr: predict_linear(node_filesystem_free{job="node"}[1h], 4 * 3600) < 0
    for: 5m
    labels:
      severity: critical
    annotations:
      title: '{{ $labels.mountpoint }} is almost full on {{ $labels.instance }}: {{ $value | humanize }}%'

  # Disk Usage - Monitoring
  - alert: NoDiskSpace
    expr: node_filesystem_avail{fstype=~"(ext.|xfs)",job="node"} / node_filesystem_size{fstype=~"(ext.|xfs)",job="node"} * 100 <= 1
    for: 15m
    labels:
      severity: critical
    annotations:
      description: There's only 1% disk space left on host {{ $labels.instance }}
      title: 'No disk space left on {{ $labels.mountpoint }} on {{ $labels.instance }}: {{ $value | humanize }}%'

  # Inode Usage - Monitoring
  - alert: HighInodeUsage
    expr: node_filesystem_files_free{fstype=~"(ext.|xfs)",job="node"} / node_filesystem_files{fstype=~"(ext.|xfs)",job="node"} * 100 <= 20
    for: 15m
    labels:
      severity: critical
    annotations:
      description: '{{ $labels.mountpoint }} inodes are running low. Please consider removing file.'
      title: 'Free inodes on $labels.instance }} on mountpoint {{ $labels.mountpoint }} is at {{ $value | printf "%.2f" }}%'

  # CPU - Monitoring
  - alert: ExtremelyHighCPU
    expr: instance:node_cpu_in_use:ratio > 0.95
    for: 2h
    labels:
      severity: critical
    annotations:
      description: 'CPU use percent is extremely high on {{ $labels.instance }} for the past 2 hours.'
      title: 'CPU use percent is extremely high on {{ $labels.instance }} for the past 2 hours.'

  # CPU - Monitoring
  - alert: HighCPU
    expr: instance:node_cpu_in_use:ratio > 0.8
    for: 2h
    labels:
      severity: critical
    annotations:
      description: 'CPU use percent is extremely high on {{ $labels.instance }} for the past 2 hours.'
      title: 'CPU use percent is high on {{ $labels.instance }} for the past 2 hours.'

  # Load Average - Monitoring
  - alert: high_load
    expr: node_load1 > 4
    for: 2m
    labels:
      severity: warn
    annotations:
      summary: "Instance {{ $labels.instance }} under high load"
      description: "{{ $labels.instance }} of job {{ $labels.job }} is under high load."

  # Memory Usage - Threshold 85%
  - alert: high_memory_load
    expr: (sum(node_memory_MemTotal_bytes) - sum(node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes) ) / sum(node_memory_MemTotal_bytes) * 100 > 85
    for: 30s
    labels:
      severity: warn
    annotations:
      summary: "Server memory is almost full"
      description: "Docker host memory usage is {{ humanize $value}}%. Reported by instance {{ $labels.instance }} of job {{ $labels.job }}"

  # Swap Usage
  - alert: swap_usage_above_50_percent
    expr: |
      (((node_memory_SwapTotal - node_memory_SwapFree) / node_memory_SwapTotal) * 100) > 50
    for: 1h
    labels:
      severity: moderate
    annotations:
      description: 'Instance {{ $labels.instance }} of job {{ $labels.job }} has swap usage above 20% (current value: {{ printf "%.2f" $value }}%) for over 1 hour'
      summary: 'Swap usage above 20%'


- name: Tools Alerts
  rules:

  # Service Grafana is down ? Alerts if not data exists
  - alert: Tool GRAFANA Down
    expr: absent(time() - container_last_seen{name="monitoring_grafana"}) < 5
    for: 15s
    labels:
      severity: critical
    annotations:
      summary: "Instance {{ $labels.instance }} down"
      description: "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 15s."

  # Service Registrator is down ? Alerts if not data exists
  - alert: Tool Registrator Down
    expr: absent(time() - container_last_seen{name="monitoring_registrator"}) < 5
    for: 15s
    labels:
      severity: critical
    annotations:
      summary: "Instance {{ $labels.instance }} down"
      description: "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 15s."

  # Service Consul is down ? Alerts if not data exists
  - alert: Tool Consul Down
    expr: absent(time() - container_last_seen{name="monitoring_consul"}) < 5
    for: 15s
    labels:
      severity: critical
    annotations:
      summary: "Instance {{ $labels.instance }} down"
      description: "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 15s."

  # Service AlertManager is down ? Alerts if not data exists
  - alert: Tool ALERT MANAGER Down
    expr: absent(time() - container_last_seen{name="monitoring_alertmanager"}) < 5
    for: 15s
    labels:
      severity: critical
    annotations:
      summary: "Instance {{ $labels.instance }} down"
      description: "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 15s."
